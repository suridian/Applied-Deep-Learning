{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "utilities.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM2NyPSQdoJKQ1gt2lCyO+Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suridian/Applied-Deep-Learning/blob/main/utilities.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_B-8_Y2YCs2J",
        "outputId": "f5031c50-02ce-4c3d-991f-f8bf958f703e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.2.10-cp37-cp37m-manylinux1_x86_64.whl (19.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.3 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.21.5)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from rasterio) (21.4.0)\n",
            "Collecting cligj>=0.5\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Collecting snuggs>=1.4.1\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Collecting affine\n",
            "  Downloading affine-2.3.1-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from rasterio) (2021.10.8)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from rasterio) (7.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rasterio) (57.4.0)\n",
            "Collecting click-plugins\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.7/dist-packages (from snuggs>=1.4.1->rasterio) (3.0.7)\n",
            "Installing collected packages: snuggs, cligj, click-plugins, affine, rasterio\n",
            "Successfully installed affine-2.3.1 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.2.10 snuggs-1.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install import-ipynb\n",
        "import import_ipynb\n",
        "\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "module = drive.CreateFile({'id':'1_bGw2qVLG_kRh4pzzceRdVHy82ANnk0C'})\n",
        "module.GetContentFile('rgb_label.ipynb')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3P2T0JmCyOv",
        "outputId": "0073e8e7-f2a2-4986-b3c7-3807f0a0c103"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting import-ipynb\n",
            "  Downloading import-ipynb-0.1.3.tar.gz (4.0 kB)\n",
            "Building wheels for collected packages: import-ipynb\n",
            "  Building wheel for import-ipynb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-py3-none-any.whl size=2975 sha256=5c000d1fbe951eb530c3704182b7c38b5fc3b85a12bc13b0b2e86d90c1ad1c6f\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/5e/dc/79780689896a056199b0b9f24471e3ee184fbd816df355d5f0\n",
            "Successfully built import-ipynb\n",
            "Installing collected packages: import-ipynb\n",
            "Successfully installed import-ipynb-0.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KVLYUm1BMn5",
        "outputId": "14d27cf7-d239-4a7e-90f3-2368c5a0f359"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "importing Jupyter notebook from rgb_label.ipynb\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import rasterio\n",
        "import glob\n",
        "import cv2\n",
        "from random import shuffle\n",
        "import os\n",
        "import scipy.misc\n",
        "import rgb_label as gen_label"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def balanced_test_val_split(main_path, data_to_add, image_size, train_size, n_classes):\n",
        "\timages_found = []\n",
        "\tlabels_found = []\n",
        "\tfor category in data_to_add:\n",
        "\t\t\n",
        "\t\tprint('Checking labels and data match in %s folder ...'%category)\n",
        "\t\tdata_path =os.path.join( main_path , 'Images' , category )\n",
        "\t\tdata_path += os.sep + '*.tif'\n",
        "\t\t \n",
        "\t\tlabels_path = os.path.join(main_path, 'Labels', category)\n",
        "\t\tlabels_path += os.sep + '*.jpg'\n",
        "\n",
        "\t\timages = glob.glob(data_path)\n",
        "\t\tlabels =  glob.glob(labels_path)\n",
        "\t\tassert len(labels) != 0\n",
        "\t\t#print('Checking if number of labeled files matches number of data image files....')\n",
        "\t\t# Check that number of labels corresponds to number of images\n",
        "\n",
        "\t\tassert len(labels) == len(images)\n",
        "\n",
        "\t\t# Check that they have the same names\n",
        "\t\tlabel_filename = []\n",
        "\t\timg_filename = []\n",
        "\n",
        "\t\tfor (i, img) in enumerate(images):\n",
        "\t\t\tlabel_filename.append(labels[i].split(os.sep)[-1].split('.')[0].replace('onehot', ''))\n",
        "\t\t\timg_filename.append(img.split(os.sep)[-1].split('.')[0]  )\n",
        "\n",
        "\n",
        "\t\tlabel_filename = sorted(label_filename)\n",
        "\t\timg_filename = sorted(img_filename)\n",
        "\t\t\n",
        "\t\tfor i in range(len(label_filename)):\n",
        "\n",
        "\t\t\tassert label_filename[i] == img_filename[i]\n",
        "\t\t\timages_found.append(  os.path.join(main_path , 'Images' , category) + os.sep + img_filename[i] + '.tif')\n",
        "\t\t\tlabels_found.append(  os.path.join(main_path , 'Labels' , category) + os.sep + label_filename[i] + '.jpg')\n",
        "\n",
        "\n",
        "\t\tprint('Names of labels and data in folder %s match perfectly, %d images found . '%(category, len(img_filename)))\n",
        "\n",
        "\t#shuffle images and labels \n",
        "\tc = list(zip(images_found,labels_found))\n",
        "\tshuffle(c)\n",
        "\timages, labels = zip(*c)\n",
        "\n",
        "\t# Read and save all images + labels + bodypart\n",
        "\timages_read = np.zeros((len(images),image_size,image_size,1),dtype=np.float32)\n",
        "\tlabels_read = np.zeros((len(labels), image_size, image_size,3),dtype=np.uint8)\n",
        "\tbodyparts = np.empty((len(images)),'S10')\n",
        "\tsplit_names = np.empty((len(images)),'S50')\n",
        "\tfor i in range(len(images)):\n",
        "\t\tfilename = images[i]\n",
        "\t\timg = rasterio.open(filename)\n",
        "\t\timg = img.read(1)\n",
        "\t\timages_read[i,...,0] = cv2.resize(img, (image_size, image_size), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "\t\tlabel_filename = labels[i]\n",
        "\t\tlabels_images = cv2.imread(label_filename)\n",
        "\n",
        "\t\tlabels_read[i,...] = scipy.misc.imresize(labels_images, (image_size,image_size,3), interp='nearest', mode=None)\n",
        "\t\tlabels_read[i,...] = np.uint8(labels_read[i,...])\n",
        "\t\tlabels_read[i,...] = 255*gen_label.get_categorical_label(labels_read[i,...], n_classes)\n",
        "\n",
        "\t\t# Clean bodyparts names\n",
        "\t\tbodypart = filename.split(os.sep)[-1].split('_')[0].lower()\n",
        "\t\tsplit_names[i] = filename.split(os.sep)[-1].split('.')[0].lower()\n",
        "\t\tif((bodypart == 'left') or (bodypart == 'right') or (bodypart == 'asg')):\n",
        "\t\t\tbodypart = filename.split(os.sep)[-1].split('_')[1]\n",
        "\t\t\tif(bodypart == 'fractured'):\n",
        "\t\t\t\tbodypart = filename.split(os.sep)[-1].split('_')[2]\n",
        "\t\t\tif(bodypart == 'lower'):\n",
        "\t\t\t\tbodypart = filename.split(os.sep)[-1].split('_')[2]\n",
        "\t\tif((bodypart == 'belly') or (bodypart == 'plate')):\n",
        "\t\t\t\tbodypart = filename.split(os.sep)[-1].split('_')[1]\n",
        "\t\tif((bodypart == 'leg') and (filename.split(os.sep)[-1].split('_')[1] == 'lamb')):\n",
        "\t\t\t\tbodypart = filename.split(os.sep)[-1].split('_')[1]              \n",
        "\t\t# Remove numbers\n",
        "\t\tbodypart = ''.join(i for i in bodypart if not i.isdigit())\n",
        "\t\tif(bodypart == 'nof'):\n",
        "\t\t\tbodypart = 'neckoffemur'\n",
        "\t\tbodypart = bodypart.split('.')[0]\n",
        "\t\tif(bodypart == 'anke'):\n",
        "\t\t\tbodypart = 'ankle'\n",
        "\t\t\t\n",
        "\t\tif(bodypart == 'lumbar'):\n",
        "\t\t\tbodypart = 'lumbarspin'\n",
        "\t\tbodypart = bodypart.encode(\"ascii\", \"ignore\")\n",
        "\t\tbodyparts[i] = bodypart\n",
        "\n",
        "\n",
        "\tunique, counts = np.unique(bodyparts, return_counts=True)\n",
        "\tunique_per_category = dict(zip(unique, counts))\n",
        "\n",
        "\t#print('There are %d different bodyparts'%len(unique_per_category))\n",
        "\n",
        "\tindices = np.arange(images_read.shape[0])\n",
        "\n",
        "\n",
        "\t# Build balanced test and validation sets\n",
        "\tone_per_class = []\n",
        "\tfor i in unique_per_category:\n",
        "\t\tsplit_category = np.where(bodyparts==i)[0].tolist()\n",
        "\t\t#pick one from each category to be part of the test set\n",
        "\t\tchosen_one_per_class = random.choice(split_category)\n",
        "\t\tindices_to_remove = np.argwhere( indices ==chosen_one_per_class)[0].tolist()\n",
        "\t\tindices = np.delete(indices, indices_to_remove)\n",
        "\t\tone_per_class.append(chosen_one_per_class)\n",
        "\n",
        "\tbodyparts_cut = bodyparts[indices]\n",
        "\tunique, counts = np.unique(bodyparts_cut, return_counts=True)\n",
        "\tunique_per_category = dict(zip(unique, counts))\n",
        "\n",
        "\t#print('Test that they are unique')\n",
        "\t#print(len(one_per_class) == len(set(one_per_class)))\n",
        "\t# From the different bodyparts left fill the test set from those that have more than one example\n",
        "\t# until test size is 0.3*total\n",
        "\n",
        "\textra_need = int((1-train_size)*len(images)) - len(one_per_class)\n",
        "\n",
        "\tcounter = 0\n",
        "\ttest_extra = []\n",
        "\twhile ( counter < extra_need ):\n",
        "\t\t#reshuffle dictionary\n",
        "\t\tkeys = list(unique_per_category.keys())\n",
        "\t\tnp.random.shuffle(keys)\n",
        "\t\tfor bodypart in keys:\n",
        "\t\t\tif ( counter >= extra_need):\n",
        "\t\t\t\tbreak\n",
        "\t\t\tif( unique_per_category[bodypart] == 1 or unique_per_category[bodypart] == 0):\n",
        "\t\t\t\tcontinue\n",
        "\n",
        "\t\t\t#get random sample of that bodypart\n",
        "\t\t\tbodypart_indices = np.where(bodyparts[indices] == bodypart)[0].tolist()\n",
        "\t\t\tbodypart_choice = random.choice(indices[bodypart_indices])\n",
        "\t\t\ttest_extra.append(bodypart_choice)\n",
        "\t\t\t#remove bodypart index to avoid repetition\n",
        "\t\t\tunique_per_category[bodypart] -= 1\n",
        "\t\t\tremove_bodypart_index = np.argwhere( indices == bodypart_choice)[0].tolist()\n",
        "\t\t\tindices = np.delete(indices, remove_bodypart_index )\n",
        "\t\t\tcounter += 1\n",
        "\t\t \n",
        "\ttest_indices = np.concatenate((one_per_class,test_extra))\n",
        "\n",
        "\timages_train = images_read[indices,...]\n",
        "\tbody_train = bodyparts[indices]\n",
        "\tsplit_names_train = split_names[indices]\n",
        "\tlabels_train = labels_read[indices,...]\n",
        "\n",
        "\trandom.shuffle(test_indices)\n",
        "\n",
        "\timages_test = images_read[test_indices[:int(len(test_indices)/2)],...]\n",
        "\tbody_test = bodyparts[test_indices[:int(len(test_indices)/2)]]\n",
        "\tsplit_names_test = split_names[test_indices[:int(len(test_indices)/2)]]\n",
        "\tlabels_test = labels_read[test_indices[:int(len(test_indices)/2)],...]\n",
        "\n",
        "\timages_val = images_read[test_indices[int(len(test_indices)/2):],...]\n",
        "\tbody_val = bodyparts[test_indices[int(len(test_indices)/2):]]\n",
        "\tsplit_names_val = split_names[test_indices[int(len(test_indices)/2):]]\n",
        "\tlabels_val = labels_read[test_indices[int(len(test_indices)/2):],...]\n",
        "\n",
        "\n",
        "\t#print(np.in1d(split_names_test, split_names_val, assume_unique=False, invert=False))\n",
        "\t#print('FINAL SHAPES')\n",
        "\t#print('train set :  %d images'%images_train.shape[0])\n",
        "\t#print('test set :  %d images'%images_test.shape[0])\n",
        "\t#print('val set :  %d images'%images_val.shape[0])\n",
        "\n",
        "\t# Check that we didn't lose images on the way\n",
        "\tassert (images_train.shape[0] + images_test.shape[0] + images_val.shape[0]) == len(images)\n",
        "\n",
        "\treturn images_train, labels_train, body_train, split_names_train, images_test, labels_test, body_test,\\\n",
        "\tsplit_names_test, images_val, labels_val, body_val, split_names_val "
      ],
      "metadata": {
        "id": "vymPlZXeDLuw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle_together_simple(images, labels, bodyparts):\n",
        "\n",
        "    c = list(zip(images,labels, bodyparts))\n",
        "    shuffle(c)\n",
        "    images, labels, bodyparts = zip(*c)    \n",
        "    images = np.asarray(images)\n",
        "    labels = np.asarray(labels)\n",
        "    bodyparts = np.asarray(bodyparts)\n",
        "    \n",
        "    return images, labels, bodyparts"
      ],
      "metadata": {
        "id": "Mx0gBbcnDQJA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle_together(images, labels, bodyparts, filenames):\n",
        "\n",
        "    c = list(zip(images,labels, bodyparts,filenames))\n",
        "    shuffle(c)\n",
        "    images, labels, bodyparts, filenames = zip(*c)    \n",
        "    images = np.asarray(images)\n",
        "    labels = np.asarray(labels)\n",
        "    bodyparts = np.asarray(bodyparts)\n",
        "    filenames = np.asarray(filenames)\n",
        "    \n",
        "    return images, labels, bodyparts, filenames"
      ],
      "metadata": {
        "id": "mQDRApe8DS0_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_crop(x, y, permin, permax):\n",
        "    h, w, _ = x.shape\n",
        "    per_h = random.uniform(permin, permax)\n",
        "    per_w = random.uniform(permin, permax)\n",
        "    crop_size = (int((1-per_h)*h),int((1-per_w)*w))\n",
        "\n",
        "    rangew = (w - crop_size[0]) // 2 if w>crop_size[0] else 0\n",
        "    rangeh = (h - crop_size[1]) // 2 if h>crop_size[1] else 0\n",
        "    offsetw = 0 if rangew == 0 else np.random.randint(rangew)\n",
        "    offseth = 0 if rangeh == 0 else np.random.randint(rangeh)\n",
        "    cropped_x = x[offseth:offseth+crop_size[0], offsetw:offsetw+crop_size[1], :]\n",
        "    cropped_y = y[offseth:offseth+crop_size[0], offsetw:offsetw+crop_size[1], :]\n",
        "    resize_x = cv2.resize(cropped_x, (h, w), interpolation=cv2.INTER_CUBIC)\n",
        "    resize_y = cv2.resize(cropped_y, (h, w), interpolation=cv2.INTER_NEAREST)\n",
        "    if cropped_y.shape[-1] == 0:\n",
        "        return x, y\n",
        "    else:\n",
        "        return np.reshape(resize_x,(h,w,1)), resize_y"
      ],
      "metadata": {
        "id": "eruDm0PBDVOg"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}